## TL;DR

## Model and Objective


## Experiments
Following optimizers are compared.
* [Adagrad](https://jmlr.org/papers/v12/duchi11a.html)
* [Adadelta](https://arxiv.org/abs/1212.5701)
* [Adam](https://arxiv.org/abs/1412.6980)
* [Adam with AMSgrad](https://arxiv.org/abs/1904.09237)
* [AdamW](https://arxiv.org/abs/1711.05101)

## Summary
